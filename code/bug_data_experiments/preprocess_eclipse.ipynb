{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Snap Inc. 2020. This sample code is made available by Snap Inc. for informational purposes only. It is provided as-is, without warranty of any kind, express or implied, including any warranties of merchantability, fitness for a particular purpose, or non-infringement. In no event will Snap Inc. be liable for any damages arising from the sample code or your use thereof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import hashlib\n",
    "import spacy\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "import itertools\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from tf_idf_vectorizer import *\n",
    "# from utils.snap_preprocessed_df_handle import *\n",
    "from utils.EstimatorSelectionHelper import EstimatorSelectionHelper\n",
    "from utils.classifier_setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('../../data/bugrepo/EclipsePlatform/eclipse_platform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/bugrepo/EclipsePlatform/train.csv').dropna().reset_index(drop=True)\n",
    "test_df = pd.read_csv('../../data/bugrepo/EclipsePlatform/test.csv').dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Duplicate'] = train_df.Duplicate.str.split(';')\n",
    "test_df['Duplicate'] = test_df.Duplicate.str.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {'id1':[], 'id2':[]}\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    dups = row['Duplicate']\n",
    "    for id2 in dups:\n",
    "        train_dict['id1'].append(row['Issue_id'])\n",
    "        train_dict['id2'].append(id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'id1':[], 'id2':[]}\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    dups = row['Duplicate']\n",
    "    for id2 in dups:\n",
    "        test_dict['id1'].append(row['Issue_id'])\n",
    "        test_dict['id2'].append(id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_dict)\n",
    "test_df = pd.DataFrame(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(row):\n",
    "    group1 = main_df[main_df['Issue_id']==int(row['id1'])]['Component'].values[0]\n",
    "    group2 = main_df[main_df['Issue_id']==int(row['id2'])]['Component'].values[0]\n",
    "    \n",
    "    if group1!=group2:\n",
    "        return None\n",
    "    else:\n",
    "        return group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_dict(group_df_train, train_df):\n",
    "    \n",
    "    final_train_dict = {'id1':[],'id2':[],'dup_issue':[],'dup_group':[],'title1':[],'title2':[]}\n",
    "    \n",
    "    for name, group in group_df_train:\n",
    "        for index, row in group.iterrows():\n",
    "            final_train_dict['id1'].append(row['id1'])\n",
    "            final_train_dict['id2'].append(row['id2'])\n",
    "            final_train_dict['dup_issue'].append(True)\n",
    "            final_train_dict['dup_group'].append(True)\n",
    "            final_train_dict['title1'].append(main_df[main_df['Issue_id']==int(row['id1'])]['Title'].values[0])\n",
    "            final_train_dict['title2'].append(main_df[main_df['Issue_id']==int(row['id2'])]['Title'].values[0])\n",
    "\n",
    "        main_same_group = main_df[main_df['Component']==name]\n",
    "        all_ids = []\n",
    "        all_ids.extend(list(group['id1']))\n",
    "        all_ids.extend(list(group['id2']))\n",
    "        all_ids = list(set(all_ids))\n",
    "        not_in_group_df = main_same_group[main_same_group[\"Issue_id\"].apply(lambda x: x not in all_ids)]\n",
    "        not_in_group_df = not_in_group_df.sample(n=len(all_ids))\n",
    "        k=int(0.2*len(all_ids))\n",
    "        same_group_diff_bug = random.sample(set(itertools.product(all_ids, list(not_in_group_df['Issue_id']))), k)\n",
    "\n",
    "        for (id1, id2) in same_group_diff_bug:\n",
    "            final_train_dict['id1'].append(id1)\n",
    "            final_train_dict['id2'].append(id2)\n",
    "            final_train_dict['dup_issue'].append(False)\n",
    "            final_train_dict['dup_group'].append(True)\n",
    "            final_train_dict['title1'].append(main_df[main_df['Issue_id']==int(id1)]['Title'].values[0])\n",
    "            final_train_dict['title2'].append(main_df[main_df['Issue_id']==int(id2)]['Title'].values[0])\n",
    "\n",
    "        remaining_k = int(0.8*len(all_ids))\n",
    "        main_not_same_group = train_df[train_df['common_group']!=name]\n",
    "        all_ids_not_same = []\n",
    "        all_ids_not_same.extend(list(group['id1']))\n",
    "        all_ids_not_same.extend(list(group['id2']))\n",
    "        all_ids_not_same = list(set(all_ids_not_same))\n",
    "        diff_group_diff_bug = random.sample(set(itertools.product(all_ids, all_ids_not_same)), remaining_k)\n",
    "\n",
    "        for (id1, id2) in diff_group_diff_bug:\n",
    "            final_train_dict['id1'].append(id1)\n",
    "            final_train_dict['id2'].append(id2)\n",
    "            final_train_dict['dup_issue'].append(False)\n",
    "            final_train_dict['dup_group'].append(False)\n",
    "            final_train_dict['title1'].append(main_df[main_df['Issue_id']==int(id1)]['Title'].values[0])\n",
    "            final_train_dict['title2'].append(main_df[main_df['Issue_id']==int(id2)]['Title'].values[0])\n",
    "            \n",
    "    \n",
    "    return final_train_dict\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['common_group'] = train_df.apply(get_groups, axis=1)\n",
    "test_df['common_group'] = test_df.apply(get_groups, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df_train = train_df.groupby('common_group')\n",
    "group_df_test = test_df.groupby('common_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_dict = get_final_dict(group_df_test, test_df)\n",
    "final_train_dict = get_final_dict(group_df_train, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = pd.DataFrame(final_train_dict)\n",
    "final_test = pd.DataFrame(final_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.to_pickle('../../data/dataframes/df_train_bugrepo_eclipse.pkl')\n",
    "final_test.to_pickle('../../data/dataframes/df_test_bugrepo_eclipse.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
